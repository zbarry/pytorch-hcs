{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e6a655b-cc0c-4d77-9564-ae98ab3ba64f",
   "metadata": {},
   "source": [
    "# Use UMAP / densMAP on CNN embeddings to find dataset outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6fe76d-acc7-473b-8629-50754cf1ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c7b4d6-f1b5-4441-9dae-cd93678a792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray\n",
    "import janitor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import umap\n",
    "import xarray as xr\n",
    "from pytorch_hcs.datasets import BBBC021DataModule\n",
    "from pytorch_hcs.models import ResNet18, ResNet101, ResNet18Embeddings\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0a57a5-32ec-49fc-80cf-f57d3bced3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data\")\n",
    "data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a419235-67e2-48c3-9814-b1673eac1ca8",
   "metadata": {},
   "source": [
    "# Choose GPU or CPU processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d824e89b-d540-48b7-a786-63bb4d55c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\"\n",
    "# DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d424fa50-cc87-490b-b226-95b781b9397b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Initialize W&B run\n",
    "\n",
    "This is only so we can load model checkpoints from W&B artifacts.\n",
    "Future TODO would be to store the results of the evaluation run in W&B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758d8f53-9af9-4542-98a4-28c5c045407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "run = wandb.init(project='pytorch-hcs', name='outliers')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b343cd61-460c-4810-bf1f-4c7c158db9c3",
   "metadata": {},
   "source": [
    "# Specify model to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b07c5b6-b4aa-4d3b-89c9-6229f7d84be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_project = 'zbarry/pytorch-hcs'\n",
    "\n",
    "model_id, model_cls = \"resnet18:latest\", ResNet18\n",
    "# model_id, model_cls = \"resnet101:latest\", ResNet101\n",
    "# model_id, model_cls = \"resnet18-embeddings:latest\", ResNet18Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3affda-6e45-407e-8489-2233d40f5711",
   "metadata": {},
   "source": [
    "# Load model\n",
    "\n",
    "Download model .ckpt file from W&B. \n",
    "Note that a model `.ckpt` file can be loaded directly through `.load_from_checkpoint` in the `data/weights` directory\n",
    "rather than downloaded from W&B, if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06529cb-968d-4e58-b8fc-8f9b050d0332",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact = run.use_artifact(\n",
    "    f\"{user_project}/{model_id}\", type=\"model\"\n",
    ")\n",
    "\n",
    "artifact_dir = artifact.download()\n",
    "\n",
    "ckpt_path = f\"{artifact_dir}/model.ckpt\"\n",
    "\n",
    "model = model_cls.load_from_checkpoint(str(ckpt_path)).eval().to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d247570-a39a-48fb-880b-e16781b08a0f",
   "metadata": {},
   "source": [
    "# Set up `LightningDataModule`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512998d1-f32c-4311-84b5-1a73d53d1745",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = BBBC021DataModule(\n",
    "    num_workers=8 if DEVICE != \"cpu\" else 0,  # pickle error with h5py otherwise\n",
    "    tv_batch_size=4,\n",
    "    t_batch_size=16,\n",
    ")\n",
    "\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9ca3fd-298a-43b4-bcf4-c9696e6099dd",
   "metadata": {},
   "source": [
    "# Extract image embeddings with our BBBC021-trained network\n",
    "\n",
    "- We skip running the features through the final classification layer.\n",
    "- All images are included (even those from compounds with unknown MoA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b35f0ff-db08-41ab-863f-289adb7fd221",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dm.all_dataset\n",
    "# dataset = dm.train_dataset\n",
    "# dataset = dm.test_dataset\n",
    "\n",
    "dataloader = dm.all_dataloader()\n",
    "# dataloader = dm.train_dataloader()\n",
    "# dataloader = dm.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30899c7a-592a-4ac9-83d3-1322ebc94b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_bbbc021 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for image_batch, _, _ in tqdm(dataloader):\n",
    "        # features from our BBBC021-trained model\n",
    "\n",
    "        features_batch = np.array(\n",
    "            model.compute_features(image_batch.to(DEVICE)).cpu()\n",
    "        )\n",
    "\n",
    "        features_bbbc021.append(features_batch)\n",
    "\n",
    "features_bbbc021 = np.concatenate(features_bbbc021, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407bf949-e672-46fb-8b58-16651ed8a11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df = dataset.image_df.transform_column(\n",
    "    \"moa\", lambda class_name: dataset.class_to_label[class_name], \"moa_label\"\n",
    ")\n",
    "image_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93204c5-a7af-4bbd-9f6a-32020dddd89c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Perform dimensionality reduction for visualization using UMAP\n",
    "\n",
    "- [UMAP article](https://pair-code.github.io/understanding-umap/)\n",
    "- We are using the [densMAP](https://umap-learn.readthedocs.io/en/latest/densmap_demo.html) implementation to push outlier points further away from inliers.\n",
    "- Try both `'cosine'` and `'euclidean'` as distance metrics.\n",
    "to see the effect on which images are the greatest outliers.\n",
    "- `n_neighboors` has been tuned ahead of time (see `notebooks/poc/umap_param_sweep.ipynb`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78d661b-6d65-4049-93f7-31ee0deac331",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised = False\n",
    "\n",
    "reducer = umap.UMAP(\n",
    "    metric='cosine',\n",
    "    n_neighbors=500,\n",
    "    min_dist=0.0,\n",
    "    n_components=2,\n",
    "    random_state=42,\n",
    "    densmap=True,\n",
    ")\n",
    "\n",
    "vis_embedding = reducer.fit_transform(\n",
    "    features_bbbc021.reshape(features_bbbc021.shape[0], -1),\n",
    "    y=image_df[\"moa_label\"] if supervised else None,\n",
    ")\n",
    "\n",
    "embedding_df = (\n",
    "    pd.concat(\n",
    "        [\n",
    "            dataset.image_df.reset_index(drop=True),\n",
    "            pd.DataFrame(vis_embedding, columns=[\"umap_x\", \"umap_y\"]),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60610b05-ba05-41e9-9762-6a831c8ab435",
   "metadata": {},
   "source": [
    "# Plot UMAP'd embeddings for compounds of known MoA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28101dd5-8d2e-4924-807a-deb32a492e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "hover_cols = [\n",
    "    \"image_idx\",\n",
    "    \"moa\",\n",
    "    \"compound\",\n",
    "    \"concentration\",\n",
    "]\n",
    "\n",
    "kwargs = dict(\n",
    "    x=\"umap_x\",\n",
    "    y=\"umap_y\",\n",
    "    hover_cols=hover_cols,\n",
    "    alpha=0.25,\n",
    "    aspect=\"equal\",\n",
    "    cmap=\"glasbey\",\n",
    "    colorbar=False,\n",
    "    width=900,\n",
    "    height=550,\n",
    ")\n",
    "\n",
    "(\n",
    "    embedding_df.query('moa != \"null\"').hvplot.scatter(\n",
    "        c=\"moa\", title=\"UMAP embedding\", **kwargs\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e5ebc0-e827-4fe6-873b-962612613b10",
   "metadata": {},
   "source": [
    "# Calculate k-nearest neighbors distance for each embedded point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267171dc-441d-4266-90c1-708528ec39d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "n_neighbors = 8\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=n_neighbors)\n",
    "nbrs.fit(embedding_df[[\"umap_x\", \"umap_y\"]])\n",
    "\n",
    "distances, indexes = nbrs.kneighbors(embedding_df[[\"umap_x\", \"umap_y\"]])\n",
    "\n",
    "distances = distances[:, 1:]\n",
    "\n",
    "avg_distances = distances.mean(1)\n",
    "\n",
    "labeled_embedding_df = embedding_df.add_columns(\n",
    "    outlier_score=avg_distances,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970437e6-6046-4695-b440-578992e2a469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf(data):\n",
    "    data_sorted = np.sort(data)\n",
    "\n",
    "    # calculate the proportional values of samples\n",
    "    p = np.arange(len(data)) / (len(data) - 1)\n",
    "    \n",
    "    return data_sorted, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab4d180-2129-4c71-ad69-2690802955ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf_x, cdf_y = ecdf(avg_distances)\n",
    "\n",
    "(\n",
    "    hv.Curve(\n",
    "        avg_distances,\n",
    "        kdims=\"BBBC021 image index\",\n",
    "        vdims=\"distance\",\n",
    "        label=\"Average kNN distance for BBBC021 image UMAP projections\",\n",
    "    ).opts(width=1000)\n",
    "    + hv.Histogram(\n",
    "        np.histogram(avg_distances, bins=200), kdims=\"distance\"\n",
    "    ).opts(width=1000)\n",
    "    + hv.Curve((cdf_x, cdf_y), kdims=\"distance\", vdims=\"ECDF\").opts(width=1000)\n",
    ").cols(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce8e211-e198-44cc-8ded-e810282d35dd",
   "metadata": {},
   "source": [
    "# View images in order of descending kNN distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92cd87d-1d76-45eb-a983-6468d7413ee6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pybbbc import BBBC021\n",
    "bbbc021 = BBBC021()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0109f8c5-af5e-43cb-b2d3-e1e054421e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_df = labeled_embedding_df.sort_values(\"outlier_score\", ascending=False)\n",
    "\n",
    "outlier_order = outlier_df[\"image_idx\"].values\n",
    "outlier_scores = outlier_df[\"outlier_score\"].values\n",
    "\n",
    "\n",
    "def make_layout(image_idx):\n",
    "    image, metadata = bbbc021[outlier_order[image_idx]]\n",
    "\n",
    "    prefix = f\"{metadata.compound.compound}, {metadata.compound.moa}, {outlier_scores[image_idx]}\"\n",
    "\n",
    "    plots = []\n",
    "\n",
    "    cmaps = [\"fire\", \"kg\", \"kb\"]\n",
    "\n",
    "    for channel_idx, im_channel in enumerate(image):\n",
    "        plot = hv.Image(\n",
    "            im_channel,\n",
    "            bounds=(0, 0, im_channel.shape[1], im_channel.shape[0]),\n",
    "            label=f\"{prefix} | {bbbc021.CHANNELS[channel_idx]}\",\n",
    "        ).opts(cmap=cmaps[channel_idx])\n",
    "        plots.append(plot)\n",
    "\n",
    "    plots.append(\n",
    "        hv.RGB(\n",
    "            image.transpose(1, 2, 0),\n",
    "            bounds=(0, 0, im_channel.shape[1], im_channel.shape[0]),\n",
    "            label=\"Channel overlay\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return hv.Layout(plots).cols(2)\n",
    "\n",
    "\n",
    "hv.DynamicMap(make_layout, kdims=\"image\").redim.range(\n",
    "    image=(0, len(bbbc021) - 1)\n",
    ").opts(hv.opts.Image(frame_width=450, aspect='equal'), hv.opts.RGB(frame_width=450, aspect='equal'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
