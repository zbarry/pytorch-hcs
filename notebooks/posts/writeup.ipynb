{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c09c78a5-5edd-4ab8-85bd-83504c80236f",
   "metadata": {},
   "source": [
    "# A scaffold for mechanism of action classification from high content screening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecec6c86-e4b8-438f-9206-005c7945db43",
   "metadata": {},
   "source": [
    "## The purpose\n",
    "\n",
    "* Provide an easy starting point to working with microscopy image analysis\n",
    "* Full stack of useful libraries for deep learning\n",
    "    * PyTorch - our autograd library of choice\n",
    "    * PyTorch-Lightning - reduces training boilerplate and provides some nifty other features\n",
    "    * [Weights & Biases](https://wandb.ai/) - a cool way to do ML experiment tracking and more "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0f8c9f-5a13-4d1e-b8ad-2c02db5f6810",
   "metadata": {},
   "source": [
    "## A little background on high content imaging / screening\n",
    "\n",
    "In a high-content screening / imaging assay, a cell line is treated with a number of different compounds (often on the order of 10k, 100k, or more molecules) for a given period of time, \n",
    "and then the cells are [fixed](https://en.wikipedia.org/wiki/Fixation_(histology)) and stained with fluorescent dyes which visualize important cellular structures that are then imaged under a microscope.\n",
    "Through this procedure, we can directly observe the impact of the given (drug) molecules on cellular morphology - \n",
    "changes in cell and subcellular shape and structure.\n",
    "The biophysical interaction by which a bioactive molecule exerts its effects on cells is known as its [mechanism of action (MoA)](https://en.wikipedia.org/wiki/Mechanism_of_action).\n",
    "Different compounds with the same MoA will have similar effects on cellular morphology, which we should be able to detect in our screen.\n",
    "Note that a molecule in fact may have more than one MoA - these [\"dirty drugs\"](https://en.wikipedia.org/wiki/Dirty_drug) may exhibit multiple effects on cellular processes in the assay simultaneously, \n",
    "or effects may change based on dosage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092e07d0-8d3c-4ddb-9316-11b5bc6b6264",
   "metadata": {},
   "source": [
    "## Our dataset: BBBC021 from the Broad Bioimage Benchmark Collection\n",
    "\n",
    "The [Broad Bioimage Benchmark Collection](https://bbbc.broadinstitute.org/) is a collection of open microscopy imaging datasets published by the [Broad Institute](https://www.broadinstitute.org/), \n",
    "an MIT- and Harvard-affiliated research institute in Cambridge, MA, USA. \n",
    "The [BBBC021 dataset](https://bbbc.broadinstitute.org/BBBC021) comprises a [high-content screening](https://en.wikipedia.org/wiki/High-content_screening) assay of [Human MCF-7 cells](https://en.wikipedia.org/wiki/MCF-7), \n",
    "a very commonly used breast cancer cell line in biomedical research.\n",
    "\n",
    "\n",
    "\n",
    "In the BBBC021 dataset, 3 structures have been stained: DNA, and the cytoskeletal proteins F-actin and B-tubulin, \n",
    "which comprise actin filaments and microtubules, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0d21fa-a25e-4fef-8fb5-8f06e85f4a59",
   "metadata": {},
   "source": [
    "## pybbbc - a Pythonic API for accessing BBBC021 images and metadata\n",
    "\n",
    "* Original repo by Giacomo Deodato: https://github.com/giacomodeodato/pybbbc\n",
    "* My fork (required for this codebase): https://github.com/zbarry/pybbbc\n",
    "\n",
    "The differences between the two versions:\n",
    "\n",
    "* Metadata dataframes for convenient wrangling and aggregation.\n",
    "* Returned metadata also returns the absolute index of the image in the full BBBC021 dataset\n",
    "(see below for discussion on absolute vs. relative index).\n",
    "* The image processing step during dataset creation does not clip the maximum intensity.\n",
    "\n",
    "### First time build of your local copy of the dataset\n",
    "\n",
    "* Raw data download\n",
    "* Dataset construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c477f0-a155-457f-9ee8-74c17174e729",
   "metadata": {},
   "source": [
    "### Working with pybbbc\n",
    "\n",
    "#### Constructing the BBBC021 object\n",
    "\n",
    "When you create the `BBBC021` object, you can choose which images to include by selecting subsets with keyword arguments. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7c0d72-9610-4145-a697-c6b9b81fb9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybbbc import BBBC021\n",
    "\n",
    "# Entire BBBC021 dataset, including unknown MoA\n",
    "\n",
    "bbbc021_all = BBBC021()\n",
    "\n",
    "# Just the images with known MoA\n",
    "\n",
    "bbbc021_moa = BBBC021(moa=[moa for moa in BBBC021.MOA if moa != \"null\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfc7787-9d7d-410f-ac58-9daefe1cc718",
   "metadata": {},
   "source": [
    "`BBBC021` has a number of useful constant class attributes that describe the entirety of the dataset\n",
    "(and can be accessed without creating an object):\n",
    "\n",
    "* `IMG_SHAPE`\n",
    "* `CHANNELS`\n",
    "* `PLATES`\n",
    "* `COMPOUNDS`\n",
    "* `MOA`\n",
    "\n",
    "These don't change with the subset of BBBC021 you have selected. On other other hand, these do:\n",
    "\n",
    "* `moa`\n",
    "* `compounds`\n",
    "* `plates`\n",
    "* `sites`\n",
    "* `wells`\n",
    "\n",
    "For example, `BBBC021.MOA` will give you a list of all the MoAs in the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0767138-bcd7-453a-96b2-ea7b019ff247",
   "metadata": {},
   "outputs": [],
   "source": [
    "BBBC021.MOA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ec6a37-ac60-4e79-9532-dd325f1a9bda",
   "metadata": {},
   "source": [
    "### Access an image and its metadata\n",
    "\n",
    "Your initialized `BBBC021` object is indexable and has a length. \n",
    "An index is the integer offset into the subset of BBBC021 you have selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2284e97-60e0-4b1f-af1a-896396ea24b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of images in BBBC021: {len(bbbc021_all)}')\n",
    "print(f'Number of images with known MoA: {len(bbbc021_moa)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce86668-01c4-4344-a699-6e3f1277a9b4",
   "metadata": {},
   "source": [
    "What you get back from the object is a `tuple` of the given image followed by its associated metadata\n",
    "in the form of a `namedtuple`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02678e0b-e091-4c68-a04c-3e0870f27d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, metadata = bbbc021_moa[0]\n",
    "\n",
    "plate, compound, image_idx = metadata  # it can be unpacked like a regular `tuple`\n",
    "\n",
    "print(f'{metadata=}\\n\\n{metadata.plate=}\\n\\n{metadata.compound=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc7eb89-9311-437c-b753-9136d8b81ecf",
   "metadata": {},
   "source": [
    "### View the metadata `DataFrame`s\n",
    "\n",
    "The metadata is compiled into two Pandas `DataFrame`s, `image_df` and `moa_df`, \n",
    "which contain only metadata from the selected subset of the BBBC021 dataset.\n",
    "\n",
    "`image_df` contains metadata information on an individual image level. \n",
    "Each row corresponds to an image in the subset of BBBC021 you selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8547d213-d246-46e7-b66b-5bf58926eef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbbc021_moa.image_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44956996-2c81-46d7-8156-803219d2931b",
   "metadata": {},
   "source": [
    "`image_idx` corresponds to the absolute index of the image in the full BBBC021 dataset.\n",
    "`relative_image_idx` is the index you would use to access the given image as in:\n",
    "\n",
    "`image, metadata = your_bbbc021_obj[relative_image_idx]`\n",
    "\n",
    "`moa_df` is a metadata `DataFrame` which provides you with all the compound-concentration pairs in the selected BBBC021 subset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e357588-d12d-4508-b11e-b5dd3383a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbbc021_moa.moa_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef347174-35a1-4b3a-a4d8-a6ba83ba322c",
   "metadata": {},
   "source": [
    "## Explore the BBBC021 dataset\n",
    "\n",
    "Visualization jiff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751fbbe6-e6aa-4c4f-ab4d-64be0322e853",
   "metadata": {},
   "source": [
    "## Training a model\n",
    "\n",
    "### Model architecture choice: ResNets\n",
    "\n",
    "### Train / val / test split\n",
    "\n",
    "* Training and validation sets get at least one compound a piece\n",
    "* Training set gets the compound with the most images, followed by validation, then test set\n",
    "* The test set will not have a compound for Eg5 inhibitor or cholesterol-lowering MoAs\n",
    "* MoAs with 4 compounds will have two sent to training set\n",
    "* DMSO will be split as closely to the desired ratio as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf42d04-bef6-4b9b-a267-5e327e64b191",
   "metadata": {},
   "source": [
    "## Evaluating model performance\n",
    "\n",
    "### Confusion matrix\n",
    "\n",
    "### Correlation score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a797ad-3d7b-41d5-84fb-d4369bb794da",
   "metadata": {},
   "source": [
    "## Applying the model\n",
    "\n",
    "### Computing image features\n",
    "\n",
    "Task-specific training vs imagenet weights\n",
    "\n",
    "Pass through penultimate layer\n",
    "\n",
    "### UMAP dimensionality reduction\n",
    "\n",
    "### Outlier detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1eee98f-dbc3-4c3e-8107-66e0cc32a0e6",
   "metadata": {},
   "source": [
    "## New directions\n",
    "\n",
    "* Semi-supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9675d88-c4e2-43d8-9be5-7c9d243f7085",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = 7\n",
    "low = 2\n",
    "high = 7\n",
    "\n",
    "(images - low) / (high - low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f553106c-0bd7-4960-bf61-e7d78cd21119",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-hcs",
   "language": "python",
   "name": "pytorch-hcs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
