{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use trained model to extract image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray\n",
    "import janitor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import umap\n",
    "import xarray as xr\n",
    "from pytorch_hcs.datasets import BBBC021DataModule\n",
    "from pytorch_hcs.models import ResNet18, ResNet18Embeddings\n",
    "from pytorch_hcs.vis import set_hv_defaults\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# from pyprojroot import here\n",
    "\n",
    "\n",
    "set_hv_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data\")  # here() / \"data\"\n",
    "data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose GPU or CPU processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\"\n",
    "# DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify model to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_name = \"resnet18-cleandata-moreaug\"\n",
    "# model_version = \"version_3d5kdlrp\"\n",
    "\n",
    "# model_cls = ResNet18\n",
    "\n",
    "run_name = \"ResNet18Embeddings\"\n",
    "# model_version = \"version_3hxtgk45\"  # version 1\n",
    "model_version = \"version_358i4dhs\"  # version 2 with dropout before last layer\n",
    "\n",
    "model_cls = ResNet18Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up `LightningDataModule`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = BBBC021DataModule(\n",
    "    num_workers=8,\n",
    "    tv_batch_size=4,\n",
    "    t_batch_size=32,\n",
    ")\n",
    "\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = data_path / f\"weights/{run_name}/{model_version}\"\n",
    "\n",
    "checkpoint_files = list(model_path.glob(\"epoch=*.ckpt\"))\n",
    "\n",
    "if len(checkpoint_files) > 1:\n",
    "    raise Exception(\"Too many checkpoint files\")\n",
    "if len(checkpoint_files) == 0:\n",
    "    raise FileNotFoundError(\"No checkpoint file exists.\")\n",
    "\n",
    "checkpoint_file = checkpoint_files[0]\n",
    "\n",
    "print(checkpoint_file)\n",
    "\n",
    "model_bbbc021 = (\n",
    "    model_cls.load_from_checkpoint(str(checkpoint_file), num_channels=3).eval().to(DEVICE)\n",
    ")\n",
    "model_imagenet = (\n",
    "    model_cls(num_classes=dm.num_classes, pretrained=True, num_channels=3).eval().to(DEVICE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate through all images across train/val/test sets, plugging into model and extracting features \n",
    "\n",
    "We skip running the features through the final classification layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dm.all_dataset\n",
    "# dataset = dm.train_dataset\n",
    "\n",
    "dataloader = dm.all_dataloader()\n",
    "# dataloader = dm.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_bbbc021 = []\n",
    "features_imagenet = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for image_batch, _, _ in tqdm(dataloader):\n",
    "        # features from our BBBC021-trained model\n",
    "\n",
    "        features_batch = np.array(\n",
    "            model_bbbc021.compute_features(image_batch.to(DEVICE)).cpu()\n",
    "        )\n",
    "\n",
    "        features_bbbc021.append(features_batch)\n",
    "\n",
    "        # features from ImageNet-trained model\n",
    "\n",
    "        features_batch = np.array(\n",
    "            model_imagenet.compute_features(image_batch.to(DEVICE)).cpu()\n",
    "        )\n",
    "\n",
    "        features_imagenet.append(features_batch)\n",
    "\n",
    "features_bbbc021 = np.concatenate(features_bbbc021, axis=0)\n",
    "features_imagenet = np.concatenate(features_imagenet, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.class_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df = dataset.image_df.transform_column(\n",
    "    \"moa\", lambda class_name: dataset.class_to_label[class_name], \"moa_label\"\n",
    ")\n",
    "image_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform dimensionality reduction for visualization using UMAP\n",
    "\n",
    "- We will r\n",
    "\n",
    "Sources: \n",
    "- https://pair-code.github.io/understanding-umap/https://pair-code.github.io/understanding-umap/\n",
    "\n",
    "# TODO: add replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    datasets=[(\"BBBC021\", features_bbbc021), (\"ImageNet\", features_imagenet)],\n",
    "    metrics=[\"euclidean\", \"cosine\"],\n",
    "    n_neighbors=[35, 100, 500, 1000],\n",
    "    densmap=[False, True],\n",
    "    supervised=[False, True],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dfs = []\n",
    "\n",
    "for (dataset_name, features), metric, n_neighbors, densmap, supervised in tqdm(\n",
    "    product(\n",
    "        params[\"datasets\"],\n",
    "        params[\"metrics\"],\n",
    "        params[\"n_neighbors\"],\n",
    "        params[\"densmap\"],\n",
    "        params[\"supervised\"],\n",
    "    ),\n",
    "    total=np.prod([len(lst) for lst in params.values()]),\n",
    "):\n",
    "    reducer = umap.UMAP(\n",
    "        metric=metric,\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=0.0,\n",
    "        n_components=2,\n",
    "        random_state=42,\n",
    "        densmap=densmap,\n",
    "    )\n",
    "\n",
    "    vis_embedding = reducer.fit_transform(\n",
    "        features.reshape(features.shape[0], -1),\n",
    "        y=image_df[\"moa_label\"] if supervised else None,\n",
    "    )\n",
    "\n",
    "    embedding_df = (\n",
    "        pd.concat(\n",
    "            [\n",
    "                dataset.image_df.reset_index(drop=True),\n",
    "                pd.DataFrame(vis_embedding, columns=[\"umap_x\", \"umap_y\"]),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        .add_columns(\n",
    "            dataset=dataset_name,\n",
    "            metric=metric,\n",
    "            n_neighbors=n_neighbors,\n",
    "            densmap=densmap,\n",
    "            supervised=supervised,\n",
    "        )\n",
    "        .reorder_columns(\n",
    "            [\"dataset\", \"metric\", \"n_neighbors\", \"densmap\", \"supervised\"]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    embedding_dfs.append(embedding_df)\n",
    "\n",
    "all_embedding_df = pd.concat(embedding_dfs, ignore_index=True).astype(\n",
    "    dict(dataset=\"category\", metric=\"category\", concentration=float)\n",
    ")\n",
    "all_embedding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embedding_df.to_parquet(data_path / 'umap_results.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hover_cols = [\n",
    "    \"image_idx\",\n",
    "    \"moa\",\n",
    "    \"compound\",\n",
    "    \"concentration\",\n",
    "    #     \"tvt_assignment\",\n",
    "]\n",
    "\n",
    "groups = [\"weights\", \"metric\", \"n_neighbors\", \"densmap\", \"supervised\"]\n",
    "\n",
    "kwargs = dict(\n",
    "    x=\"umap_x\",\n",
    "    y=\"umap_y\",\n",
    "    hover_cols=hover_cols,\n",
    "    alpha=0.25,\n",
    "    aspect=\"equal\",\n",
    "    cmap=\"glasbey\",\n",
    "    colorbar=False,\n",
    "    width=900,\n",
    "    height=550,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    all_embedding_df.rename_column(\"dataset\", \"weights\")\n",
    "    .query('moa != \"null\"')\n",
    "    .hvplot.scatter(\n",
    "        c=\"moa\",\n",
    "        title=\"UMAP embedding | {dimensions}\",\n",
    "        groupby=groups,\n",
    "        **kwargs\n",
    "    )\n",
    "    .opts(fontsize=dict(title=10))\n",
    "    .layout(groups)\n",
    "    .cols(2)\n",
    "    .opts(\n",
    "        shared_axes=False,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the one we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'cosine'\n",
    "n_neighbors = 500\n",
    "densmap = True\n",
    "supervised = False\n",
    "\n",
    "dataset_name, features = \"BBBC021\", features_bbbc021\n",
    "\n",
    "reducer = umap.UMAP(\n",
    "    metric=metric,\n",
    "    n_neighbors=n_neighbors,\n",
    "    min_dist=0.0,\n",
    "    n_components=2,\n",
    "    random_state=42,\n",
    "    densmap=densmap,\n",
    ")\n",
    "\n",
    "vis_embedding = reducer.fit_transform(\n",
    "    features.reshape(features.shape[0], -1),\n",
    "    y=image_df[\"moa_label\"] if supervised else None,\n",
    ")\n",
    "\n",
    "embedding_df = (\n",
    "    pd.concat(\n",
    "        [\n",
    "            dataset.image_df.reset_index(drop=True),\n",
    "            pd.DataFrame(vis_embedding, columns=[\"umap_x\", \"umap_y\"]),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    .add_columns(\n",
    "        dataset=dataset_name,\n",
    "        metric=metric,\n",
    "        n_neighbors=n_neighbors,\n",
    "        densmap=densmap,\n",
    "        supervised=supervised,\n",
    "    )\n",
    "    .reorder_columns(\n",
    "        [\"dataset\", \"metric\", \"n_neighbors\", \"densmap\", \"supervised\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_df = (\n",
    "#     all_embedding_df.query('dataset == \"BBBC021\" and metric == \"cosine\" and n_neighbors == 500 and densmap == True and supervised == False')\n",
    "#     .copy()\n",
    "#     .reset_index(drop=True)\n",
    "# )\n",
    "# embedding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    embedding_df.query('moa != \"null\"').hvplot.scatter(\n",
    "        c=\"moa\", title=\"UMAP embedding\", **kwargs\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_ = kwargs.copy()\n",
    "kwargs_.pop(\"cmap\")\n",
    "kwargs_.pop(\"colorbar\")\n",
    "\n",
    "(\n",
    "    embedding_df.query('moa != \"null\"').hvplot.scatter(\n",
    "        c=\"plate\", title=\"UMAP embedding\", cmap='glasbey',  **kwargs_\n",
    "    )\n",
    ")\n",
    "\n",
    "# (\n",
    "#     embedding_df.query('moa != \"null\"').hvplot.scatter(\n",
    "#         c=\"site\", title=\"UMAP embedding\", cmap='glasbey', colorbar=True, **kwargs_\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make another plot but color the dots by whether they were predicted correctly in the test set or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINDING: COSINE DISTANCE ESSENTIAL TO FINDING USEFUL OUTLIERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN mean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf(data):\n",
    "    data_sorted = np.sort(data)\n",
    "\n",
    "    # calculate the proportional values of samples\n",
    "    p = np.arange(len(data)) / (len(data) - 1)\n",
    "    \n",
    "    return data_sorted, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=8)\n",
    "nbrs.fit(embedding_df[[\"umap_x\", \"umap_y\"]])\n",
    "\n",
    "distances, indexes = nbrs.kneighbors(embedding_df[[\"umap_x\", \"umap_y\"]])\n",
    "\n",
    "distances = distances[:, 1:]\n",
    "\n",
    "avg_distances = distances.mean(1)\n",
    "\n",
    "cdf_x, cdf_y = ecdf(avg_distances)\n",
    "\n",
    "(\n",
    "    hv.Curve(\n",
    "        avg_distances,\n",
    "        kdims=\"BBBC021 image index\",\n",
    "        vdims=\"distance\",\n",
    "        label=\"Average kNN distance for BBBC021 image UMAP projections\",\n",
    "    ).opts(width=1000)\n",
    "    + hv.Histogram(np.histogram(avg_distances, bins=200), kdims='distance').opts(width=1000)\n",
    "    + hv.Curve((cdf_x, cdf_y), kdims='distance', vdims='ECDF').opts(width=1000)\n",
    ").cols(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_embedding_df = embedding_df.add_columns(\n",
    "    outlier_score=avg_distances,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_ = kwargs.copy()\n",
    "kwargs_.pop(\"cmap\")\n",
    "kwargs_.pop(\"colorbar\")\n",
    "kwargs_.pop(\"alpha\")\n",
    "\n",
    "(\n",
    "    labeled_embedding_df.hvplot.scatter(\n",
    "        c=\"outlier_score\",\n",
    "        title=\"Average kNN distance\",\n",
    "        cmap=\"jet\",\n",
    "        colorbar=True,\n",
    "        logz=True,\n",
    "        alpha=0.5,\n",
    "        **kwargs_\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybbbc import BBBC021\n",
    "\n",
    "bbbc021 = BBBC021()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_df = labeled_embedding_df.sort_values(\"outlier_score\", ascending=False)\n",
    "outlier_order = outlier_df[\"image_idx\"].values\n",
    "outlier_scores = outlier_df[\"outlier_score\"].values\n",
    "\n",
    "\n",
    "def make_layout(image_idx):\n",
    "    image, metadata = bbbc021[outlier_order[image_idx]]\n",
    "\n",
    "    #     prefix = f\"{metadata.compound.compound} @ {metadata.compound.concentration:.2e} μM, {metadata.compound.moa}\"\n",
    "\n",
    "    prefix = f\"{metadata.compound.compound}, {metadata.compound.moa}, {outlier_scores[image_idx]}\"\n",
    "\n",
    "    plots = []\n",
    "\n",
    "    cmaps = [\"fire\", \"kg\", \"kb\"]\n",
    "\n",
    "    for channel_idx, im_channel in enumerate(image):\n",
    "        plot = hv.Image(\n",
    "            im_channel,\n",
    "            bounds=(0, 0, im_channel.shape[1], im_channel.shape[0]),\n",
    "            label=f\"{prefix} | {bbbc021.CHANNELS[channel_idx]}\",\n",
    "        ).opts(cmap=cmaps[channel_idx])\n",
    "        plots.append(plot)\n",
    "\n",
    "    plots.append(\n",
    "        hv.RGB(\n",
    "            image.transpose(1, 2, 0),\n",
    "            bounds=(0, 0, im_channel.shape[1], im_channel.shape[0]),\n",
    "            label=\"Channel overlay\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return hv.Layout(plots).cols(2)\n",
    "\n",
    "\n",
    "hv.DynamicMap(make_layout, kdims=\"image\").redim.range(\n",
    "    image=(0, len(bbbc021) - 1)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-hcs",
   "language": "python",
   "name": "pytorch-hcs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
